import torch.nn as nn
import torch

class PONO(nn.Module):
    def __init__(self, input_size=None, return_stats=False, affine=True, eps=1e-5):
        super(PONO, self).__init__()
        self.return_stats = return_stats
        self.input_size = input_size
        self.eps = eps
        self.affine = affine

        if affine:
            self.beta = nn.Parameter(torch.zeros(1, 1, *input_size))
            self.gamma = nn.Parameter(torch.ones(1, 1, *input_size))
        else:
            self.beta, self.gamma = None, None

    def forward(self, x):
        mean = x.mean(dim=1, keepdim=True)
        std = (x.var(dim=1, keepdim=True) + self.eps).sqrt()
        x = (x - mean) / std
        if self.affine:
            x = x * self.gamma + self.beta
        return x[0, :, :, :, :]#, mean, std

class MetaAconC(nn.Module):
    r""" ACON activation (activate or not).
    MetaAconC: (p1*x-p2*x) * sigmoid(beta*(p1*x-p2*x)) + p2*x, beta is generated by a small network
    according to "Activate or Not: Learning Customized Activation" <https://arxiv.org/pdf/2009.04759.pdf>.
    """

    def __init__(self, c1, k=1, s=1, r=16):  # ch_in, kernel, stride, r
        super().__init__()
        c2 = max(r, c1 // r)
        self.p1 = nn.Parameter(torch.randn(1, c1, 1, 1))
        self.p2 = nn.Parameter(torch.randn(1, c1, 1, 1))
        self.fc1 = nn.Conv2d(c1, c2, k, s, bias=True)
        self.fc2 = nn.Conv2d(c2, c1, k, s, bias=True)
        # self.bn1 = nn.BatchNorm2d(c2)
        # self.bn2 = nn.BatchNorm2d(c1)

    def forward(self, x):
        y = x.mean(dim=2, keepdims=True).mean(dim=3, keepdims=True)
        # batch-size 1 bug/instabilities https://github.com/ultralytics/yolov5/issues/2891
        # beta = torch.sigmoid(self.bn2(self.fc2(self.bn1(self.fc1(y)))))  # bug/unstable
        beta = torch.sigmoid(self.fc2(self.fc1(y)))  # bug patch BN layers removed
        dpx = (self.p1 - self.p2) * x
        result = dpx * torch.sigmoid(beta * dpx) + self.p2 * x
        return result

class Involution(nn.Module):
    def __init__(self, channels, kernel_size=7, stride=1, group_channels=16, reduction_ratio=4):
        super().__init__()
        assert not (channels % group_channels or channels % reduction_ratio)

        # in_c=out_c
        self.channels = channels
        self.kernel_size = kernel_size
        self.stride = stride

        # 每组多少个通道
        self.group_channels = group_channels
        self.groups = channels // group_channels

        # reduce channels
        self.reduce = nn.Sequential(
            nn.Conv2d(channels, channels // reduction_ratio, 1),
            nn.BatchNorm2d(channels // reduction_ratio),
            nn.ReLU()
        )
        # span channels
        self.span = nn.Conv2d(
            channels // reduction_ratio,
            self.groups * kernel_size ** 2,
            1
        )

        self.down_sample = nn.AvgPool2d(stride) if stride != 1 else nn.Identity()
        self.unfold = nn.Unfold(kernel_size, padding=(kernel_size - 1) // 2, stride=stride)

    def forward(self, x):
        # Note that 'h', 'w' are height & width of the output feature.

        # generate involution kernel: (b,G*K*K,h,w)
        weight_matrix = self.span(self.reduce(self.down_sample(x)))
        
        b, _, h, w = weight_matrix.shape
        # unfold input: (b,C*K*K,h,w)
        x_unfolded = self.unfold(x)
        
        # (b,G*K*K,h,w) -> (b,G,1,K*K,h,w)
        weight_matrix = weight_matrix.view(b, self.groups, 1, self.kernel_size*self.kernel_size, h, w)
        # (b,C*K*K,h,w)->(b,G,C//G,K*K,h,w)
        unfolded = x_unfolded.view(b, self.groups, self.group_channels, self.kernel_size*self.kernel_size, h, w)
        # (b,G,C//G,h,w)
        mul_add = (weight_matrix * unfolded).sum(dim=3)
        # (b,C,h,w)
        out = mul_add.view(b, self.channels, h, w)

        return out

class AlexNet(nn.Module):
    #类ALEXNET继承nn.module这个父类
    def __init__(self, num_classes=1000, init_weights=False):
        #通过初始化函数，定义网络在正向传播过程中需要使用的层结构
        #num_classes是指输出的图片种类个数，init_weights=False意味着不定义模型中的初始权重
        super(AlexNet, self).__init__()
        #nn.Sequential模块，可以将一系列的层结构进行打包，组合成一个新的结构，
        # 将专门用于提取图像特征的结构的名称取为features
        self.features1 = nn.Sequential(
            nn.Conv2d(3, 48, kernel_size=9, stride=4, padding=2),
            # input[3, 224, 224]  output[48, 55, 55]
            #第一个卷积层，彩色图片深度为3，卷积核个数位48，卷积核大小11，步长4，padding2
            MetaAconC(c1=48),
            PONO(input_size=[48, 55, 55]),
            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[48, 20, 20]

            nn.Conv2d(48, 128, kernel_size=5,padding=2),#步长默认为1，当步长为1时不用设置# output[128, 27, 27]
            MetaAconC(c1=128),
            PONO(input_size=[128, 27, 27]),
            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 13, 13]

            nn.Conv2d(128, 192, kernel_size=3, padding=1),          # output[192, 13, 13]
            MetaAconC(c1=192),

            nn.Conv2d(192, 192, kernel_size=3, padding=1),          # output[192, 13, 13]
            MetaAconC(c1=192),

            nn.Conv2d(192, 128, kernel_size=3, padding=1),          # output[128, 13, 13]
            MetaAconC(c1=128),
            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 6, 6]
        )
        self.features2 = nn.Sequential(
            nn.Conv2d(3, 48, kernel_size=1, stride=1),
            Involution(48, kernel_size=11, stride=4),
            # input[3, 224, 224]  output[48, 61, 61]
            #第一个卷积层，彩色图片深度为3，卷积核个数位48，卷积核大小11，步长4，padding2
            #MetaAconC(c1=48),
            #PONO(input_size=[48, 56, 56]),
            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[48, 20, 20]

            nn.Conv2d(48, 128, kernel_size=1, stride=1),
            Involution(128, kernel_size=5, stride=1),#步长默认为1，当步长为1时不用设置# output[128, 27, 27]
            #MetaAconC(c1=128),
            #PONO(input_size=[128, 27, 27]),
            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 13, 13]

            nn.Conv2d(128, 192, kernel_size=1, stride=1),
            Involution(192, kernel_size=3, stride=1), # output[192, 13, 13]
            #MetaAconC(c1=192),

            nn.Conv2d(192, 192, kernel_size=1, stride=1),
            Involution(192, kernel_size=3, stride=1),# output[192, 13, 13]
            #MetaAconC(c1=192),
            nn.Conv2d(192, 128, kernel_size=1, stride=1),# output[128, 13, 13]
            #MetaAconC(c1=128),
            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 6, 6]
        )
        #将三个全连接层打包成一个新的模块，分类器
        self.classifier = nn.Sequential(
            nn.Dropout(p=0.5),#随机将一半的节点失活，默认为0.5
            nn.Linear(2*128 * 6 * 6, 2048),#将特征矩阵展平，128*6*6最后输出的长*宽*高，2048为全连接层节点个数
            nn.ReLU(inplace=True),#Relu激活函数
            nn.Dropout(p=0.5),
            nn.Linear(2048, 2048),#全连接层2的输入为全连接层1的输出2048，全连接层2的节点个数2048
            nn.ReLU(inplace=True),
            nn.Linear(2048, num_classes),#全连接层3的输入为全连接层2的输出2048
            #全连接层最后的输出就是图片类别的个数
        )
        if init_weights:
            self._initialize_weights()
        #是否初始化权重，如果初始化函数中的init_weights=Ture,就会进入到初始化权重的函数


    def forward(self, x):
        #forward正向传播过程，x为输入的变量
        x1 = self.features1(x)
        x2 = self.features2(x)
        #将训练样本输入features
        x1 = torch.flatten(x1, start_dim=1)
        x2 = torch.flatten(x2, start_dim=1)
        x = torch.cat((x1, x2),1)
        #将输入的变量进行展平从深度高度宽度三个维度进行展开，索引从1开始，展成一个一维向量
        x = self.classifier(x)
        #将展平后的数据输入到分类器中（三个全连接层组成的）
        return x#最后的输出为图片类别

    #初始化权重的函数
    def _initialize_weights(self):
        for m in self.modules():#遍历self.modules这样一个模块，该模块继承自它的父类nn.module，该模块会迭代每一个层次
            if isinstance(m, nn.Conv2d):#如果该层次是一个卷积层，就会使用kaiming_normal_这样一个方法初始化权重
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)#如果偏值不为空的话，就用0对权重进行初始化
            elif isinstance(m, nn.Linear):#如果该层次是一个全连接层，就用normal进行初始化
                nn.init.normal_(m.weight, 0, 0.01)#正态分布对权重进行赋值，均值为0，方差为0.01
                nn.init.constant_(m.bias, 0)#设置全连接层的偏值为0
